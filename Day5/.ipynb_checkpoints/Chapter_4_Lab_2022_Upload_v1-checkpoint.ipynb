{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4   Writing Structured Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "### Term Frequency Inverse document frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code is adapted from https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text summarization using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Along the way, you will consolidate your knowledge of fundamental programming constructs, learn more about using features of the Python language in a natural and concise way, and learn some useful techniques in visualizing natural language data. As before, this chapter contains many examples and exercises (and as before, some exercises introduce new material). Readers new to programming should work through them carefully and consult other introductions to programming if necessary; experienced programmers can quickly skim this chapter.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text) # NLTK function\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Along the way, you will consolidate your knowledge of fundamental programming constructs, learn more about using features of the Python language in a natural and concise way, and learn some useful techniques in visualizing natural language data.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Along the way, you will consolidate your knowledge of fundamental programming constructs, learn more about using features of the Python language in a natural and concise way, and learn some useful techniques in visualizing natural language data.',\n",
       " 'As before, this chapter contains many examples and exercises (and as before, some exercises introduce new material).',\n",
       " 'Readers new to programming should work through them carefully and consult other introductions to programming if necessary; experienced programmers can quickly skim this chapter.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As before, this chapter contains many examples and exercises (and as before, some exercises introduce new material).'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Readers new to programming should work through them carefully and consult other introductions to programming if necessary; experienced programmers can quickly skim this chapter.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create the Frequency matrix of the words in each sentence. (see slides)\n",
    "#### We calculate the frequency of words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Frequency matrix of the words in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Along the way, ': {'along': 1, 'way': 2, ',': 3, 'consolid': 1, 'knowledg': 1, 'fundament': 1, 'program': 1, 'construct': 1, 'learn': 2, 'use': 2, 'featur': 1, 'python': 1, 'languag': 2, 'natur': 2, 'concis': 1, 'techniqu': 1, 'visual': 1, 'data': 1, '.': 1}, 'As before, this': {'befor': 2, ',': 2, 'thi': 1, 'chapter': 1, 'contain': 1, 'mani': 1, 'exampl': 1, 'exercis': 2, '(': 1, 'introduc': 1, 'new': 1, 'materi': 1, ')': 1, '.': 1}, 'Readers new to ': {'reader': 1, 'new': 1, 'program': 2, 'work': 1, 'care': 1, 'consult': 1, 'introduct': 1, 'necessari': 1, ';': 1, 'experienc': 1, 'programm': 1, 'quickli': 1, 'skim': 1, 'thi': 1, 'chapter': 1, '.': 1}}\n"
     ]
    }
   ],
   "source": [
    "freq_matrix = _create_frequency_matrix(sentences)\n",
    "print(freq_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, each sentence is the key and the value is a dictionary of word frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate TermFrequency and generate a matrix\n",
    "#### We’ll find the TermFrequency for each word in a sentence.\n",
    "#### Now, remember the definition of TF,\n",
    "#### TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "#### Here, the document is a sentence, the term is a word in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Calculate TermFrequency and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Along the way, ': {'along': 0.05263157894736842, 'way': 0.10526315789473684, ',': 0.15789473684210525, 'consolid': 0.05263157894736842, 'knowledg': 0.05263157894736842, 'fundament': 0.05263157894736842, 'program': 0.05263157894736842, 'construct': 0.05263157894736842, 'learn': 0.10526315789473684, 'use': 0.10526315789473684, 'featur': 0.05263157894736842, 'python': 0.05263157894736842, 'languag': 0.10526315789473684, 'natur': 0.10526315789473684, 'concis': 0.05263157894736842, 'techniqu': 0.05263157894736842, 'visual': 0.05263157894736842, 'data': 0.05263157894736842, '.': 0.05263157894736842}, 'As before, this': {'befor': 0.14285714285714285, ',': 0.14285714285714285, 'thi': 0.07142857142857142, 'chapter': 0.07142857142857142, 'contain': 0.07142857142857142, 'mani': 0.07142857142857142, 'exampl': 0.07142857142857142, 'exercis': 0.14285714285714285, '(': 0.07142857142857142, 'introduc': 0.07142857142857142, 'new': 0.07142857142857142, 'materi': 0.07142857142857142, ')': 0.07142857142857142, '.': 0.07142857142857142}, 'Readers new to ': {'reader': 0.0625, 'new': 0.0625, 'program': 0.125, 'work': 0.0625, 'care': 0.0625, 'consult': 0.0625, 'introduct': 0.0625, 'necessari': 0.0625, ';': 0.0625, 'experienc': 0.0625, 'programm': 0.0625, 'quickli': 0.0625, 'skim': 0.0625, 'thi': 0.0625, 'chapter': 0.0625, '.': 0.0625}}\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we compare this table with the table we’ve generated in step 2, you will see the words having the same frequency are having the similar TF score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Creating a table for documents per words\n",
    "#### This again a simple table which helps in calculating IDF matrix.\n",
    "#### we calculate, “how many sentences contain a word”, Let’s call it Documents per words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. creating table for documents per words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'along': 1, 'way': 1, ',': 2, 'consolid': 1, 'knowledg': 1, 'fundament': 1, 'program': 2, 'construct': 1, 'learn': 1, 'use': 1, 'featur': 1, 'python': 1, 'languag': 1, 'natur': 1, 'concis': 1, 'techniqu': 1, 'visual': 1, 'data': 1, '.': 3, 'befor': 1, 'thi': 2, 'chapter': 2, 'contain': 1, 'mani': 1, 'exampl': 1, 'exercis': 1, '(': 1, 'introduc': 1, 'new': 2, 'materi': 1, ')': 1, 'reader': 1, 'work': 1, 'care': 1, 'consult': 1, 'introduct': 1, 'necessari': 1, ';': 1, 'experienc': 1, 'programm': 1, 'quickli': 1, 'skim': 1}\n"
     ]
    }
   ],
   "source": [
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "print(count_doc_per_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Calculate IDF and generate a matrix\n",
    "#### We’ll find the IDF for each word in a sentence.\n",
    "#### Now, remember the definition of IDF,\n",
    "#### IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "#### Here, the document is sentence, the term is a word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Calculate IDF and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Along the way, ': {'along': 0.47712125471966244, 'way': 0.47712125471966244, ',': 0.17609125905568124, 'consolid': 0.47712125471966244, 'knowledg': 0.47712125471966244, 'fundament': 0.47712125471966244, 'program': 0.17609125905568124, 'construct': 0.47712125471966244, 'learn': 0.47712125471966244, 'use': 0.47712125471966244, 'featur': 0.47712125471966244, 'python': 0.47712125471966244, 'languag': 0.47712125471966244, 'natur': 0.47712125471966244, 'concis': 0.47712125471966244, 'techniqu': 0.47712125471966244, 'visual': 0.47712125471966244, 'data': 0.47712125471966244, '.': 0.0}, 'As before, this': {'befor': 0.47712125471966244, ',': 0.17609125905568124, 'thi': 0.17609125905568124, 'chapter': 0.17609125905568124, 'contain': 0.47712125471966244, 'mani': 0.47712125471966244, 'exampl': 0.47712125471966244, 'exercis': 0.47712125471966244, '(': 0.47712125471966244, 'introduc': 0.47712125471966244, 'new': 0.17609125905568124, 'materi': 0.47712125471966244, ')': 0.47712125471966244, '.': 0.0}, 'Readers new to ': {'reader': 0.47712125471966244, 'new': 0.17609125905568124, 'program': 0.17609125905568124, 'work': 0.47712125471966244, 'care': 0.47712125471966244, 'consult': 0.47712125471966244, 'introduct': 0.47712125471966244, 'necessari': 0.47712125471966244, ';': 0.47712125471966244, 'experienc': 0.47712125471966244, 'programm': 0.47712125471966244, 'quickli': 0.47712125471966244, 'skim': 0.47712125471966244, 'thi': 0.17609125905568124, 'chapter': 0.17609125905568124, '.': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "print(idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Calculate TF-IDF and generate a matrix\n",
    "#### Now we have both the matrix and the next step is very easy.\n",
    "#### TF-IDF algorithm is made of 2 algorithms multiplied together.\n",
    "#### In simple terms, we are multiplying the values from both the matrix and generating new matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Calculate TF-IDF and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Along the way, ': {'along': 0.02511164498524539, 'way': 0.05022328997049078, ',': 0.027803883008791774, 'consolid': 0.02511164498524539, 'knowledg': 0.02511164498524539, 'fundament': 0.02511164498524539, 'program': 0.009267961002930591, 'construct': 0.02511164498524539, 'learn': 0.05022328997049078, 'use': 0.05022328997049078, 'featur': 0.02511164498524539, 'python': 0.02511164498524539, 'languag': 0.05022328997049078, 'natur': 0.05022328997049078, 'concis': 0.02511164498524539, 'techniqu': 0.02511164498524539, 'visual': 0.02511164498524539, 'data': 0.02511164498524539, '.': 0.0}, 'As before, this': {'befor': 0.06816017924566606, ',': 0.025155894150811604, 'thi': 0.012577947075405802, 'chapter': 0.012577947075405802, 'contain': 0.03408008962283303, 'mani': 0.03408008962283303, 'exampl': 0.03408008962283303, 'exercis': 0.06816017924566606, '(': 0.03408008962283303, 'introduc': 0.03408008962283303, 'new': 0.012577947075405802, 'materi': 0.03408008962283303, ')': 0.03408008962283303, '.': 0.0}, 'Readers new to ': {'reader': 0.029820078419978902, 'new': 0.011005703690980077, 'program': 0.022011407381960155, 'work': 0.029820078419978902, 'care': 0.029820078419978902, 'consult': 0.029820078419978902, 'introduct': 0.029820078419978902, 'necessari': 0.029820078419978902, ';': 0.029820078419978902, 'experienc': 0.029820078419978902, 'programm': 0.029820078419978902, 'quickli': 0.029820078419978902, 'skim': 0.029820078419978902, 'thi': 0.011005703690980077, 'chapter': 0.011005703690980077, '.': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Score the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring a sentence is differs with different algorithms. Here, we are using Tf-IDF score of words in a sentence to give weight to the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Important Algorithm: score the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Along the way, ': 0.029706125721151354, 'As before, this': 0.03126933723058517, 'Readers new to ': 0.023940586317166775}\n"
     ]
    }
   ],
   "source": [
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Find the threshold\n",
    "#### Similar to any summarization algorithms, there can be different ways to calculate a threshold value. We’re calculating the average sentence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Find the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0283053497563011\n"
     ]
    }
   ],
   "source": [
    "threshold = _find_average_score(sentence_scores)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Generate the summary\n",
    "#### Algorithm: Select a sentence for a summarization if the sentence score is more than the average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=_generate_summary(sentences, sentence_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Along the way, you will consolidate your knowledge of fundamental programming constructs, learn more about using features of the Python language in a natural and concise way, and learn some useful techniques in visualizing natural language data. As before, this chapter contains many examples and exercises (and as before, some exercises introduce new material).\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1   Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far, we have seen two kinds of sequence object: strings and lists. Another kind of sequence is called a tuple. Tuples are formed with the comma operator, and typically enclosed using parentheses. We've actually seen them in the previous chapters, and sometimes referred to them as \"pairs\", since there were always two members. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, tuples can have any number of members. Like lists and strings, tuples can be indexed and sliced, and have a length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'walk', 'fem', 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'fem', 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fem', 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare strings, lists and tuples directly, and do the indexing, slice, and length operation on each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'I turned off the spectroroute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (6, 'turned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[-3:], text[-3:], pair[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Various ways to iterate over sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Expression\tComment\n",
    "#### for item in s\titerate over the items of s\n",
    "#### for item in sorted(s)\titerate over the items of s in order\n",
    "#### for item in set(s)\titerate over unique elements of s\n",
    "#### for item in reversed(s)\titerate over elements of s in reverse\n",
    "#### for item in set(s).difference(t)\titerate over elements of s not in t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can convert between these sequence types. For example, tuple(s) converts any kind of sequence into a tuple, and list(s) converts any kind of sequence into a list. We can convert a list of strings to a single string using the join() function, e.g. ':'.join(words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I',\n",
       " ' ',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'p',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'r',\n",
       " 'o',\n",
       " 'r',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " 'e')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I', 'turned', 'off', 'the', 'spectroroute')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' ',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'p',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'r',\n",
       " 'o',\n",
       " 'r',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " 'e']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 'turned']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I:turned:off:the:spectroroute'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "':'.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some other objects, such as a FreqDist, can be converted into a sequence (using list() or sorted()) and support iteration, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'lorry',\n",
       " ',',\n",
       " 'yellow',\n",
       " 'lorry',\n",
       " ',',\n",
       " 'red',\n",
       " 'lorry',\n",
       " ',',\n",
       " 'yellow',\n",
       " 'lorry',\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'lorry': 4, ',': 3, 'yellow': 2, 'Red': 1, 'red': 1, '.': 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorry', ',', 'yellow', 'Red', 'red', '.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lorry: 4; ,: 3; yellow: 2; Red: 1; red: 1; .: 1; "
     ]
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(key + ':', fdist[key], end='; ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next example, we use tuples to re-arrange the contents of our list. (We can omit the parentheses because the comma has higher precedence than assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[2], words[3], words[4] = words[3], words[4], words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "(words[2], words[3], words[4]) = (words[3], words[4], words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'spectroroute', 'off', 'the']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Use tuples to rearrange the contents of a list (from: Ex=[\"we\",\"take\",\"into\",\"account\",\"this\",\"fact\"]) to Ex=[\"we\",\"take\",\"this\",\"fact\",\"into\",\"account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=[\"we\", \"are\", \"going\",\"to\",\"hiking\",\"tomorrow\",\"with\",\"Lisa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen[0], sen[3], sen[5] = sen[5], sen[3], sen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomorrow', 'are', 'going', 'to', 'hiking', 'we', 'with', 'Lisa']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an idiomatic and readable way to move items inside a list. It is equivalent to the following traditional way of doing such tasks that does not use tuples (notice that this method needs a temporary variable tmp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[2] = words[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[3] = words[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[4] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are also functions that modify the structure of a sequence and which can be handy for language processing. Thus, zip() takes the items of two or more sequences and \"zips\" them together into a single list of tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=['noun', 'verb', 'prep', 'det', 'noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x248c5f13c80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a sequence s, enumerate(s) returns pairs consisting of an index and the item at that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For some NLP tasks it is necessary to cut up a sequence into two or more parts. For instance, we might want to \"train\" a system on 90% of the data and test it on the remaining 10%. To do this we decide the location where we want to cut the data [1], then cut the sequence at that location [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.nps_chat.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(0.9 * len(text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2. Please divide names corpus into two parts. (95% of the data is used to \"train\" the model and 5% of data is used to test the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abagael',\n",
       " 'Abagail',\n",
       " 'Abbe',\n",
       " 'Abbey',\n",
       " 'Abbi',\n",
       " 'Abbie',\n",
       " 'Abby',\n",
       " 'Abigael',\n",
       " 'Abigail',\n",
       " 'Abigale',\n",
       " 'Abra',\n",
       " 'Acacia',\n",
       " 'Ada',\n",
       " 'Adah',\n",
       " 'Adaline',\n",
       " 'Adara',\n",
       " 'Addie',\n",
       " 'Addis',\n",
       " 'Adel',\n",
       " 'Adela',\n",
       " 'Adelaide',\n",
       " 'Adele',\n",
       " 'Adelice',\n",
       " 'Adelina',\n",
       " 'Adelind',\n",
       " 'Adeline',\n",
       " 'Adella',\n",
       " 'Adelle',\n",
       " 'Adena',\n",
       " 'Adey',\n",
       " 'Adi',\n",
       " 'Adiana',\n",
       " 'Adina',\n",
       " 'Adora',\n",
       " 'Adore',\n",
       " 'Adoree',\n",
       " 'Adorne',\n",
       " 'Adrea',\n",
       " 'Adria',\n",
       " 'Adriaens',\n",
       " 'Adrian',\n",
       " 'Adriana',\n",
       " 'Adriane',\n",
       " 'Adrianna',\n",
       " 'Adrianne',\n",
       " 'Adrien',\n",
       " 'Adriena',\n",
       " 'Adrienne',\n",
       " 'Aeriel',\n",
       " 'Aeriela',\n",
       " 'Aeriell',\n",
       " 'Ag',\n",
       " 'Agace',\n",
       " 'Agata',\n",
       " 'Agatha',\n",
       " 'Agathe',\n",
       " 'Aggi',\n",
       " 'Aggie',\n",
       " 'Aggy',\n",
       " 'Agna',\n",
       " 'Agnella',\n",
       " 'Agnes',\n",
       " 'Agnese',\n",
       " 'Agnesse',\n",
       " 'Agneta',\n",
       " 'Agnola',\n",
       " 'Agretha',\n",
       " 'Aida',\n",
       " 'Aidan',\n",
       " 'Aigneis',\n",
       " 'Aila',\n",
       " 'Aile',\n",
       " 'Ailee',\n",
       " 'Aileen',\n",
       " 'Ailene',\n",
       " 'Ailey',\n",
       " 'Aili',\n",
       " 'Ailina',\n",
       " 'Ailyn',\n",
       " 'Aime',\n",
       " 'Aimee',\n",
       " 'Aimil',\n",
       " 'Aina',\n",
       " 'Aindrea',\n",
       " 'Ainslee',\n",
       " 'Ainsley',\n",
       " 'Ainslie',\n",
       " 'Ajay',\n",
       " 'Alaine',\n",
       " 'Alameda',\n",
       " 'Alana',\n",
       " 'Alanah',\n",
       " 'Alane',\n",
       " 'Alanna',\n",
       " 'Alayne',\n",
       " 'Alberta',\n",
       " 'Albertina',\n",
       " 'Albertine',\n",
       " 'Albina',\n",
       " 'Alecia',\n",
       " 'Aleda',\n",
       " 'Aleece',\n",
       " 'Aleecia',\n",
       " 'Aleen',\n",
       " 'Alejandra',\n",
       " 'Alejandrina',\n",
       " 'Alena',\n",
       " 'Alene',\n",
       " 'Alessandra',\n",
       " 'Aleta',\n",
       " 'Alethea',\n",
       " 'Alex',\n",
       " 'Alexa',\n",
       " 'Alexandra',\n",
       " 'Alexandrina',\n",
       " 'Alexi',\n",
       " 'Alexia',\n",
       " 'Alexina',\n",
       " 'Alexine',\n",
       " 'Alexis',\n",
       " 'Alfie',\n",
       " 'Alfreda',\n",
       " 'Ali',\n",
       " 'Alia',\n",
       " 'Alica',\n",
       " 'Alice',\n",
       " 'Alicea',\n",
       " 'Alicia',\n",
       " 'Alida',\n",
       " 'Alidia',\n",
       " 'Alina',\n",
       " 'Aline',\n",
       " 'Alis',\n",
       " 'Alisa',\n",
       " 'Alisha',\n",
       " 'Alison',\n",
       " 'Alissa',\n",
       " 'Alisun',\n",
       " 'Alix',\n",
       " 'Aliza',\n",
       " 'Alla',\n",
       " 'Alleen',\n",
       " 'Allegra',\n",
       " 'Allene',\n",
       " 'Alli',\n",
       " 'Allianora',\n",
       " 'Allie',\n",
       " 'Allina',\n",
       " 'Allis',\n",
       " 'Allison',\n",
       " 'Allissa',\n",
       " 'Allsun',\n",
       " 'Ally',\n",
       " 'Allyce',\n",
       " 'Allyn',\n",
       " 'Allys',\n",
       " 'Allyson',\n",
       " 'Alma',\n",
       " 'Almeda',\n",
       " 'Almeria',\n",
       " 'Almeta',\n",
       " 'Almira',\n",
       " 'Almire',\n",
       " 'Aloise',\n",
       " 'Aloisia',\n",
       " 'Aloysia',\n",
       " 'Alpa',\n",
       " 'Alta',\n",
       " 'Althea',\n",
       " 'Alvera',\n",
       " 'Alvina',\n",
       " 'Alvinia',\n",
       " 'Alvira',\n",
       " 'Alyce',\n",
       " 'Alyda',\n",
       " 'Alys',\n",
       " 'Alysa',\n",
       " 'Alyse',\n",
       " 'Alysia',\n",
       " 'Alyson',\n",
       " 'Alyss',\n",
       " 'Alyssa',\n",
       " 'Amabel',\n",
       " 'Amabelle',\n",
       " 'Amalea',\n",
       " 'Amalee',\n",
       " 'Amaleta',\n",
       " 'Amalia',\n",
       " 'Amalie',\n",
       " 'Amalita',\n",
       " 'Amalle',\n",
       " 'Amanda',\n",
       " 'Amandi',\n",
       " 'Amandie',\n",
       " 'Amandy',\n",
       " 'Amara',\n",
       " 'Amargo',\n",
       " 'Amata',\n",
       " 'Amber',\n",
       " 'Amberly',\n",
       " 'Ambrosia',\n",
       " 'Ambur',\n",
       " 'Ame',\n",
       " 'Amelia',\n",
       " 'Amelie',\n",
       " 'Amelina',\n",
       " 'Ameline',\n",
       " 'Amelita',\n",
       " 'Ami',\n",
       " 'Amie',\n",
       " 'Amity',\n",
       " 'Ammamaria',\n",
       " 'Amy',\n",
       " 'Ana',\n",
       " 'Anabel',\n",
       " 'Anabella',\n",
       " 'Anabelle',\n",
       " 'Anais',\n",
       " 'Analiese',\n",
       " 'Analise',\n",
       " 'Anallese',\n",
       " 'Anallise',\n",
       " 'Anastasia',\n",
       " 'Anastasie',\n",
       " 'Anastassia',\n",
       " 'Anatola',\n",
       " 'Andee',\n",
       " 'Andi',\n",
       " 'Andie',\n",
       " 'Andra',\n",
       " 'Andrea',\n",
       " 'Andreana',\n",
       " 'Andree',\n",
       " 'Andrei',\n",
       " 'Andria',\n",
       " 'Andriana',\n",
       " 'Andriette',\n",
       " 'Andromache',\n",
       " 'Andromeda',\n",
       " 'Andy',\n",
       " 'Anestassia',\n",
       " 'Anet',\n",
       " 'Anett',\n",
       " 'Anetta',\n",
       " 'Anette',\n",
       " 'Ange',\n",
       " 'Angel',\n",
       " 'Angela',\n",
       " 'Angele',\n",
       " 'Angelia',\n",
       " 'Angelica',\n",
       " 'Angelika',\n",
       " 'Angelina',\n",
       " 'Angeline',\n",
       " 'Angelique',\n",
       " 'Angelita',\n",
       " 'Angelle',\n",
       " 'Angie',\n",
       " 'Angil',\n",
       " 'Angy',\n",
       " 'Ania',\n",
       " 'Anica',\n",
       " 'Anissa',\n",
       " 'Anita',\n",
       " 'Anitra',\n",
       " 'Anja',\n",
       " 'Anjanette',\n",
       " 'Anjela',\n",
       " 'Ann',\n",
       " 'Ann-Mari',\n",
       " 'Ann-Marie',\n",
       " 'Anna',\n",
       " 'Anna-Diana',\n",
       " 'Anna-Diane',\n",
       " 'Anna-Maria',\n",
       " 'Annabal',\n",
       " 'Annabel',\n",
       " 'Annabela',\n",
       " 'Annabell',\n",
       " 'Annabella',\n",
       " 'Annabelle',\n",
       " 'Annadiana',\n",
       " 'Annadiane',\n",
       " 'Annalee',\n",
       " 'Annalena',\n",
       " 'Annaliese',\n",
       " 'Annalisa',\n",
       " 'Annalise',\n",
       " 'Annalyse',\n",
       " 'Annamari',\n",
       " 'Annamaria',\n",
       " 'Annamarie',\n",
       " 'Anne',\n",
       " 'Anne-Corinne',\n",
       " 'Anne-Mar',\n",
       " 'Anne-Marie',\n",
       " 'Annecorinne',\n",
       " 'Anneliese',\n",
       " 'Annelise',\n",
       " 'Annemarie',\n",
       " 'Annetta',\n",
       " 'Annette',\n",
       " 'Anni',\n",
       " 'Annice',\n",
       " 'Annie',\n",
       " 'Annissa',\n",
       " 'Annmaria',\n",
       " 'Annmarie',\n",
       " 'Annnora',\n",
       " 'Annora',\n",
       " 'Anny',\n",
       " 'Anselma',\n",
       " 'Ansley',\n",
       " 'Anstice',\n",
       " 'Anthe',\n",
       " 'Anthea',\n",
       " 'Anthia',\n",
       " 'Antoinette',\n",
       " 'Antonella',\n",
       " 'Antonetta',\n",
       " 'Antonia',\n",
       " 'Antonie',\n",
       " 'Antonietta',\n",
       " 'Antonina',\n",
       " 'Anya',\n",
       " 'Aphrodite',\n",
       " 'Appolonia',\n",
       " 'April',\n",
       " 'Aprilette',\n",
       " 'Ara',\n",
       " 'Arabel',\n",
       " 'Arabela',\n",
       " 'Arabele',\n",
       " 'Arabella',\n",
       " 'Arabelle',\n",
       " 'Arda',\n",
       " 'Ardath',\n",
       " 'Ardeen',\n",
       " 'Ardelia',\n",
       " 'Ardelis',\n",
       " 'Ardella',\n",
       " 'Ardelle',\n",
       " 'Arden',\n",
       " 'Ardene',\n",
       " 'Ardenia',\n",
       " 'Ardine',\n",
       " 'Ardis',\n",
       " 'Ardith',\n",
       " 'Ardra',\n",
       " 'Ardyce',\n",
       " 'Ardys',\n",
       " 'Ardyth',\n",
       " 'Aretha',\n",
       " 'Ariadne',\n",
       " 'Ariana',\n",
       " 'Arianne',\n",
       " 'Aridatha',\n",
       " 'Ariel',\n",
       " 'Ariela',\n",
       " 'Ariella',\n",
       " 'Arielle',\n",
       " 'Arlana',\n",
       " 'Arlee',\n",
       " 'Arleen',\n",
       " 'Arlen',\n",
       " 'Arlena',\n",
       " 'Arlene',\n",
       " 'Arleta',\n",
       " 'Arlette',\n",
       " 'Arleyne',\n",
       " 'Arlie',\n",
       " 'Arliene',\n",
       " 'Arlina',\n",
       " 'Arlinda',\n",
       " 'Arline',\n",
       " 'Arly',\n",
       " 'Arlyn',\n",
       " 'Arlyne',\n",
       " 'Aryn',\n",
       " 'Ashely',\n",
       " 'Ashlee',\n",
       " 'Ashleigh',\n",
       " 'Ashlen',\n",
       " 'Ashley',\n",
       " 'Ashli',\n",
       " 'Ashlie',\n",
       " 'Ashly',\n",
       " 'Asia',\n",
       " 'Astra',\n",
       " 'Astrid',\n",
       " 'Astrix',\n",
       " 'Atalanta',\n",
       " 'Athena',\n",
       " 'Athene',\n",
       " 'Atlanta',\n",
       " 'Atlante',\n",
       " 'Auberta',\n",
       " 'Aubine',\n",
       " 'Aubree',\n",
       " 'Aubrette',\n",
       " 'Aubrey',\n",
       " 'Aubrie',\n",
       " 'Aubry',\n",
       " 'Audi',\n",
       " 'Audie',\n",
       " 'Audra',\n",
       " 'Audre',\n",
       " 'Audrey',\n",
       " 'Audrie',\n",
       " 'Audry',\n",
       " 'Audrye',\n",
       " 'Audy',\n",
       " 'Augusta',\n",
       " 'Auguste',\n",
       " 'Augustina',\n",
       " 'Augustine',\n",
       " 'Aura',\n",
       " 'Aurea',\n",
       " 'Aurel',\n",
       " 'Aurelea',\n",
       " 'Aurelia',\n",
       " 'Aurelie',\n",
       " 'Auria',\n",
       " 'Aurie',\n",
       " 'Aurilia',\n",
       " 'Aurlie',\n",
       " 'Auroora',\n",
       " 'Aurora',\n",
       " 'Aurore',\n",
       " 'Austin',\n",
       " 'Austina',\n",
       " 'Austine',\n",
       " 'Ava',\n",
       " 'Aveline',\n",
       " 'Averil',\n",
       " 'Averyl',\n",
       " 'Avie',\n",
       " 'Avis',\n",
       " 'Aviva',\n",
       " 'Avivah',\n",
       " 'Avril',\n",
       " 'Avrit',\n",
       " 'Ayn',\n",
       " 'Bab',\n",
       " 'Babara',\n",
       " 'Babette',\n",
       " 'Babita',\n",
       " 'Babs',\n",
       " 'Bambi',\n",
       " 'Bambie',\n",
       " 'Bamby',\n",
       " 'Barb',\n",
       " 'Barbabra',\n",
       " 'Barbara',\n",
       " 'Barbara-Anne',\n",
       " 'Barbaraanne',\n",
       " 'Barbe',\n",
       " 'Barbee',\n",
       " 'Barbette',\n",
       " 'Barbey',\n",
       " 'Barbi',\n",
       " 'Barbie',\n",
       " 'Barbra',\n",
       " 'Barby',\n",
       " 'Bari',\n",
       " 'Barrie',\n",
       " 'Barry',\n",
       " 'Basia',\n",
       " 'Bathsheba',\n",
       " 'Batsheva',\n",
       " 'Bea',\n",
       " 'Beatrice',\n",
       " 'Beatrisa',\n",
       " 'Beatrix',\n",
       " 'Beatriz',\n",
       " 'Beau',\n",
       " 'Bebe',\n",
       " 'Becca',\n",
       " 'Becka',\n",
       " 'Becki',\n",
       " 'Beckie',\n",
       " 'Becky',\n",
       " 'Bee',\n",
       " 'Beilul',\n",
       " 'Beitris',\n",
       " 'Bekki',\n",
       " 'Bel',\n",
       " 'Belia',\n",
       " 'Belicia',\n",
       " 'Belinda',\n",
       " 'Belita',\n",
       " 'Bell',\n",
       " 'Bella',\n",
       " 'Bellamy',\n",
       " 'Bellanca',\n",
       " 'Belle',\n",
       " 'Bellina',\n",
       " 'Belva',\n",
       " 'Belvia',\n",
       " 'Bendite',\n",
       " 'Benedetta',\n",
       " 'Benedicta',\n",
       " 'Benedikta',\n",
       " 'Benetta',\n",
       " 'Benita',\n",
       " 'Benni',\n",
       " 'Bennie',\n",
       " 'Benny',\n",
       " 'Benoite',\n",
       " 'Berenice',\n",
       " 'Beret',\n",
       " 'Berget',\n",
       " 'Berna',\n",
       " 'Bernadene',\n",
       " 'Bernadette',\n",
       " 'Bernadina',\n",
       " 'Bernadine',\n",
       " 'Bernardina',\n",
       " 'Bernardine',\n",
       " 'Bernelle',\n",
       " 'Bernete',\n",
       " 'Bernetta',\n",
       " 'Bernette',\n",
       " 'Berni',\n",
       " 'Bernice',\n",
       " 'Bernie',\n",
       " 'Bernita',\n",
       " 'Berny',\n",
       " 'Berri',\n",
       " 'Berrie',\n",
       " 'Berry',\n",
       " 'Bert',\n",
       " 'Berta',\n",
       " 'Berte',\n",
       " 'Bertha',\n",
       " 'Berthe',\n",
       " 'Berti',\n",
       " 'Bertie',\n",
       " 'Bertina',\n",
       " 'Bertine',\n",
       " 'Berty',\n",
       " 'Beryl',\n",
       " 'Beryle',\n",
       " 'Bess',\n",
       " 'Bessie',\n",
       " 'Bessy',\n",
       " 'Beth',\n",
       " 'Bethanne',\n",
       " 'Bethany',\n",
       " 'Bethena',\n",
       " 'Bethina',\n",
       " 'Betsey',\n",
       " 'Betsy',\n",
       " 'Betta',\n",
       " 'Bette',\n",
       " 'Bette-Ann',\n",
       " 'Betteann',\n",
       " 'Betteanne',\n",
       " 'Betti',\n",
       " 'Bettie',\n",
       " 'Bettina',\n",
       " 'Bettine',\n",
       " 'Betty',\n",
       " 'Bettye',\n",
       " 'Beulah',\n",
       " 'Bev',\n",
       " 'Beverie',\n",
       " 'Beverlee',\n",
       " 'Beverlie',\n",
       " 'Beverly',\n",
       " 'Bevvy',\n",
       " 'Bianca',\n",
       " 'Bianka',\n",
       " 'Biddy',\n",
       " 'Bidget',\n",
       " 'Bill',\n",
       " 'Billi',\n",
       " 'Billie',\n",
       " 'Billy',\n",
       " 'Binni',\n",
       " 'Binnie',\n",
       " 'Binny',\n",
       " 'Bird',\n",
       " 'Birdie',\n",
       " 'Birgit',\n",
       " 'Birgitta',\n",
       " 'Blair',\n",
       " 'Blaire',\n",
       " 'Blake',\n",
       " 'Blakelee',\n",
       " 'Blakeley',\n",
       " 'Blanca',\n",
       " 'Blanch',\n",
       " 'Blancha',\n",
       " 'Blanche',\n",
       " 'Blinni',\n",
       " 'Blinnie',\n",
       " 'Blinny',\n",
       " 'Bliss',\n",
       " 'Blisse',\n",
       " 'Blithe',\n",
       " 'Blondell',\n",
       " 'Blondelle',\n",
       " 'Blondie',\n",
       " 'Blondy',\n",
       " 'Blythe',\n",
       " 'Bo',\n",
       " 'Bobbette',\n",
       " 'Bobbi',\n",
       " 'Bobbie',\n",
       " 'Bobby',\n",
       " 'Bobette',\n",
       " 'Bobina',\n",
       " 'Bobine',\n",
       " 'Bobinette',\n",
       " 'Bonita',\n",
       " 'Bonnee',\n",
       " 'Bonni',\n",
       " 'Bonnie',\n",
       " 'Bonny',\n",
       " 'Brana',\n",
       " 'Brandais',\n",
       " 'Brande',\n",
       " 'Brandea',\n",
       " 'Brandi',\n",
       " 'Brandice',\n",
       " 'Brandie',\n",
       " 'Brandise',\n",
       " 'Brandy',\n",
       " 'Brea',\n",
       " 'Breanne',\n",
       " 'Brear',\n",
       " 'Bree',\n",
       " 'Breena',\n",
       " 'Bren',\n",
       " 'Brena',\n",
       " 'Brenda',\n",
       " 'Brenn',\n",
       " 'Brenna',\n",
       " 'Brett',\n",
       " 'Bria',\n",
       " 'Briana',\n",
       " 'Brianna',\n",
       " 'Brianne',\n",
       " 'Bride',\n",
       " 'Bridget',\n",
       " 'Bridgett',\n",
       " 'Bridgette',\n",
       " 'Bridie',\n",
       " 'Brier',\n",
       " 'Brietta',\n",
       " 'Brigid',\n",
       " 'Brigida',\n",
       " 'Brigit',\n",
       " 'Brigitta',\n",
       " 'Brigitte',\n",
       " 'Brina',\n",
       " 'Briney',\n",
       " 'Briny',\n",
       " 'Brit',\n",
       " 'Brita',\n",
       " 'Britaney',\n",
       " 'Britani',\n",
       " 'Briteny',\n",
       " 'Britney',\n",
       " 'Britni',\n",
       " 'Britt',\n",
       " 'Britta',\n",
       " 'Brittan',\n",
       " 'Brittany',\n",
       " 'Britte',\n",
       " 'Brittney',\n",
       " 'Brook',\n",
       " 'Brooke',\n",
       " 'Brooks',\n",
       " 'Brunella',\n",
       " 'Brunhilda',\n",
       " 'Brunhilde',\n",
       " 'Bryana',\n",
       " 'Bryn',\n",
       " 'Bryna',\n",
       " 'Brynn',\n",
       " 'Brynna',\n",
       " 'Brynne',\n",
       " 'Buffy',\n",
       " 'Bunni',\n",
       " 'Bunnie',\n",
       " 'Bunny',\n",
       " 'Burta',\n",
       " 'Cabrina',\n",
       " 'Cacilia',\n",
       " 'Cacilie',\n",
       " 'Caitlin',\n",
       " 'Caitrin',\n",
       " 'Cal',\n",
       " 'Calida',\n",
       " 'Calla',\n",
       " 'Calley',\n",
       " 'Calli',\n",
       " 'Callida',\n",
       " 'Callie',\n",
       " 'Cally',\n",
       " 'Calypso',\n",
       " 'Cam',\n",
       " 'Camala',\n",
       " 'Camel',\n",
       " 'Camella',\n",
       " 'Camellia',\n",
       " 'Cameo',\n",
       " 'Cami',\n",
       " 'Camila',\n",
       " 'Camile',\n",
       " 'Camilla',\n",
       " 'Camille',\n",
       " 'Cammi',\n",
       " 'Cammie',\n",
       " 'Cammy',\n",
       " 'Canada',\n",
       " 'Candace',\n",
       " 'Candi',\n",
       " 'Candice',\n",
       " 'Candida',\n",
       " 'Candide',\n",
       " 'Candie',\n",
       " 'Candis',\n",
       " 'Candra',\n",
       " 'Candy',\n",
       " 'Cappella',\n",
       " 'Caprice',\n",
       " 'Cara',\n",
       " 'Caralie',\n",
       " 'Caren',\n",
       " 'Carena',\n",
       " 'Caresa',\n",
       " 'Caressa',\n",
       " 'Caresse',\n",
       " 'Carey',\n",
       " 'Cari',\n",
       " 'Caria',\n",
       " 'Carie',\n",
       " 'Caril',\n",
       " 'Carilyn',\n",
       " 'Carin',\n",
       " 'Carina',\n",
       " 'Carine',\n",
       " 'Cariotta',\n",
       " 'Carissa',\n",
       " 'Carita',\n",
       " 'Caritta',\n",
       " 'Carla',\n",
       " 'Carlee',\n",
       " 'Carleen',\n",
       " 'Carlen',\n",
       " 'Carlena',\n",
       " 'Carlene',\n",
       " 'Carley',\n",
       " 'Carli',\n",
       " 'Carlie',\n",
       " 'Carlin',\n",
       " 'Carlina',\n",
       " 'Carline',\n",
       " 'Carlisle',\n",
       " 'Carlita',\n",
       " 'Carlota',\n",
       " 'Carlotta',\n",
       " 'Carly',\n",
       " 'Carlye',\n",
       " 'Carlyn',\n",
       " 'Carlynn',\n",
       " 'Carlynne',\n",
       " 'Carma',\n",
       " 'Carmel',\n",
       " 'Carmela',\n",
       " 'Carmelia',\n",
       " 'Carmelina',\n",
       " 'Carmelita',\n",
       " 'Carmella',\n",
       " 'Carmelle',\n",
       " 'Carmen',\n",
       " 'Carmina',\n",
       " 'Carmine',\n",
       " 'Carmita',\n",
       " 'Carmon',\n",
       " 'Caro',\n",
       " 'Carol',\n",
       " 'Carol-Jean',\n",
       " 'Carola',\n",
       " 'Carolan',\n",
       " 'Carolann',\n",
       " 'Carole',\n",
       " 'Carolee',\n",
       " 'Caroleen',\n",
       " 'Carolie',\n",
       " 'Carolin',\n",
       " 'Carolina',\n",
       " 'Caroline',\n",
       " 'Caroljean',\n",
       " 'Carolyn',\n",
       " 'Carolyne',\n",
       " 'Carolynn',\n",
       " 'Caron',\n",
       " 'Carree',\n",
       " 'Carri',\n",
       " 'Carrie',\n",
       " 'Carrissa',\n",
       " 'Carrol',\n",
       " 'Carroll',\n",
       " 'Carry',\n",
       " 'Cary',\n",
       " 'Caryl',\n",
       " 'Caryn',\n",
       " 'Casandra',\n",
       " 'Casey',\n",
       " 'Casi',\n",
       " 'Casia',\n",
       " 'Casie',\n",
       " 'Cass',\n",
       " 'Cassandra',\n",
       " 'Cassandre',\n",
       " 'Cassandry',\n",
       " 'Cassaundra',\n",
       " 'Cassey',\n",
       " 'Cassi',\n",
       " 'Cassie',\n",
       " 'Cassondra',\n",
       " 'Cassy',\n",
       " 'Cat',\n",
       " 'Catarina',\n",
       " 'Cate',\n",
       " 'Caterina',\n",
       " 'Catha',\n",
       " 'Catharina',\n",
       " 'Catharine',\n",
       " 'Cathe',\n",
       " 'Cathee',\n",
       " 'Catherin',\n",
       " 'Catherina',\n",
       " 'Catherine',\n",
       " 'Cathi',\n",
       " 'Cathie',\n",
       " 'Cathleen',\n",
       " 'Cathlene',\n",
       " 'Cathrin',\n",
       " 'Cathrine',\n",
       " 'Cathryn',\n",
       " 'Cathy',\n",
       " 'Cathyleen',\n",
       " 'Cati',\n",
       " 'Catie',\n",
       " 'Catina',\n",
       " 'Catlaina',\n",
       " 'Catlee',\n",
       " 'Catlin',\n",
       " 'Catrina',\n",
       " 'Catriona',\n",
       " 'Caty',\n",
       " 'Cayla',\n",
       " 'Cecelia',\n",
       " 'Cecil',\n",
       " 'Cecile',\n",
       " 'Ceciley',\n",
       " 'Cecilia',\n",
       " 'Cecilla',\n",
       " 'Cecily',\n",
       " 'Ceil',\n",
       " 'Cele',\n",
       " 'Celene',\n",
       " 'Celesta',\n",
       " 'Celeste',\n",
       " 'Celestia',\n",
       " 'Celestina',\n",
       " 'Celestine',\n",
       " 'Celestyn',\n",
       " 'Celestyna',\n",
       " 'Celia',\n",
       " 'Celie',\n",
       " 'Celina',\n",
       " 'Celinda',\n",
       " 'Celine',\n",
       " 'Celinka',\n",
       " 'Celisse',\n",
       " 'Celle',\n",
       " 'Cesya',\n",
       " 'Chad',\n",
       " 'Chanda',\n",
       " 'Chandal',\n",
       " 'Chandra',\n",
       " 'Channa',\n",
       " 'Chantal',\n",
       " 'Chantalle',\n",
       " 'Charil',\n",
       " 'Charin',\n",
       " 'Charis',\n",
       " 'Charissa',\n",
       " 'Charisse',\n",
       " 'Charita',\n",
       " 'Charity',\n",
       " 'Charla',\n",
       " 'Charlean',\n",
       " 'Charleen',\n",
       " 'Charlena',\n",
       " 'Charlene',\n",
       " 'Charline',\n",
       " 'Charlot',\n",
       " 'Charlott',\n",
       " 'Charlotta',\n",
       " 'Charlotte',\n",
       " 'Charmain',\n",
       " 'Charmaine',\n",
       " 'Charmane',\n",
       " 'Charmian',\n",
       " 'Charmine',\n",
       " 'Charmion',\n",
       " 'Charo',\n",
       " 'Charyl',\n",
       " 'Chastity',\n",
       " 'Chelsae',\n",
       " 'Chelsea',\n",
       " 'Chelsey',\n",
       " 'Chelsie',\n",
       " 'Chelsy',\n",
       " 'Cher',\n",
       " 'Chere',\n",
       " 'Cherey',\n",
       " 'Cheri',\n",
       " 'Cherianne',\n",
       " 'Cherice',\n",
       " 'Cherida',\n",
       " 'Cherie',\n",
       " 'Cherilyn',\n",
       " 'Cherilynn',\n",
       " 'Cherin',\n",
       " 'Cherise',\n",
       " 'Cherish',\n",
       " 'Cherlyn',\n",
       " 'Cherri',\n",
       " 'Cherrita',\n",
       " 'Cherry',\n",
       " 'Chery',\n",
       " 'Cherye',\n",
       " 'Cheryl',\n",
       " 'Cheslie',\n",
       " 'Chiarra',\n",
       " 'Chickie',\n",
       " 'Chicky',\n",
       " 'Chiquita',\n",
       " 'Chloe',\n",
       " 'Chloette',\n",
       " 'Chloris',\n",
       " 'Chris',\n",
       " 'Chriss',\n",
       " 'Chrissa',\n",
       " 'Chrissie',\n",
       " 'Chrissy',\n",
       " 'Christa',\n",
       " 'Christabel',\n",
       " 'Christabella',\n",
       " 'Christabelle',\n",
       " 'Christal',\n",
       " 'Christalle',\n",
       " 'Christan',\n",
       " 'Christean',\n",
       " 'Christel',\n",
       " 'Christen',\n",
       " 'Christi',\n",
       " 'Christian',\n",
       " 'Christiana',\n",
       " 'Christiane',\n",
       " 'Christie',\n",
       " 'Christin',\n",
       " 'Christina',\n",
       " 'Christine',\n",
       " 'Christy',\n",
       " 'Christyna',\n",
       " 'Chrysa',\n",
       " 'Chrysler',\n",
       " 'Chrystal',\n",
       " 'Chryste',\n",
       " 'Chrystel',\n",
       " 'Ciara',\n",
       " 'Cicely',\n",
       " 'Cicily',\n",
       " 'Ciel',\n",
       " 'Cilka',\n",
       " 'Cinda',\n",
       " 'Cindee',\n",
       " 'Cindelyn',\n",
       " 'Cinderella',\n",
       " 'Cindi',\n",
       " 'Cindie',\n",
       " 'Cindra',\n",
       " 'Cindy',\n",
       " 'Cinnamon',\n",
       " 'Cissie',\n",
       " 'Cissy',\n",
       " 'Clair',\n",
       " 'Claire',\n",
       " 'Clara',\n",
       " 'Clarabelle',\n",
       " 'Clare',\n",
       " ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.names.words()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7546"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = int(0.95 * len(text)) \n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(training_data) / len(text),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(test_data) / len(text),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Different Sequence Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's combine our knowledge of these three sequence types, together with list comprehensions, to perform the task of sorting the words in a string by their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'I turned off the spectroroute'.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'off', 'the', 'spectroroute']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlens = [(len(word), word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'I'), (6, 'turned'), (3, 'off'), (3, 'the'), (12, 'spectroroute')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'I'), (3, 'off'), (3, 'the'), (6, 'turned'), (12, 'spectroroute')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(w for (_,w) in wordlens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each of the above lines of code contains a significant feature. A simple string is actually an object with methods defined on it such as split() [1]. We use a list comprehension to build a list of tuples [2], where each tuple consists of a number (the word length) and the word, e.g. (3, 'the'). We use the sort() method [3] to sort the list in-place. Finally, we discard the length information and join the words back into a single string [4]. (The underscore [4] is just a regular Python variable, but we can use underscore by convention to indicate that we will not use its value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We began by talking about the commonalities in these sequence types, but the above code illustrates important differences in their roles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list is typically a sequence of objects all having the same type, of arbitrary length. We often use lists to hold sequences of words. In contrast, a tuple is typically a collection of objects of different types, of fixed length. We often use a tuple to hold a record, a collection of different fields relating to some entity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This distinction between the use of lists and tuples takes some getting used to, so here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = [\n",
    "        ('the', 'det', ['Di:', 'D@']),\n",
    "        ('off', 'prep', ['Qf', 'O:f'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, a lexicon is represented as a list because it is a collection of objects of a single type — lexical entries — of no predetermined length. An individual entry is represented as a tuple because it is a collection of objects with different interpretations, such as the orthographic form, the part of speech, and the pronunciations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A good way to decide when to use tuples vs lists is to ask whether the interpretation of an item depends on its position. For example, a tagged token combines two strings having different interpretation, and we choose to interpret the first item as the token and the second item as the tag. Thus we use tuples like this: ('class', 'noun'); a tuple of the form ('noun', 'class') would be nonsensical since it would be a word noun tagged class. In contrast, the elements of a text are all tokens, and position is not significant. Thus we use lists like this: ['venetian', 'blind']; a list of the form ['blind', 'venetian'] would be equally valid. The linguistic meaning of the words might be different, but the interpretation of list items as tokens is unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distinction between lists and tuples has been described in terms of usage. However, there is a more fundamental difference: in Python, lists are mutable, while tuples are immutable. In other words, lists can be modified, while tuples cannot. Here are some of the operations on lists that do in-place modification of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('off', 'prep', ['Qf', 'O:f']), ('the', 'det', ['Di:', 'D@'])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    " del lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turned', 'VBD', ['t3:nd', 't3`nd'])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We've been making heavy use of list comprehensions, for compact and readable processing of texts. Here's an example where we tokenize and normalize a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\n",
    "  \"it means just what I choose it to mean - neither more nor less.\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " '``',\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppose we now want to process these words further. We can do this by inserting the above expression inside a call to some other function , but Python allows us to omit the brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"''\",\n",
       " \"''\",\n",
       " ',',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '``',\n",
       " '``',\n",
       " 'a',\n",
       " 'a',\n",
       " 'choose',\n",
       " 'dumpty',\n",
       " 'humpty',\n",
       " 'i',\n",
       " 'i',\n",
       " 'in',\n",
       " 'it',\n",
       " 'it',\n",
       " 'just',\n",
       " 'less',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'more',\n",
       " 'neither',\n",
       " 'nor',\n",
       " 'rather',\n",
       " 'said',\n",
       " 'scornful',\n",
       " 'to',\n",
       " 'tone',\n",
       " 'use',\n",
       " 'what',\n",
       " 'when',\n",
       " 'word']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([w.lower() for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in nltk.word_tokenize(text)]) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(w.lower() for w in nltk.word_tokenize(text)) #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second line uses a generator expression. This is more than a notational convenience: in many language processing situations, generator expressions will be more efficient. In [1], storage for the list object must be allocated before the value of max() is computed. If the text is very large, this could be slow. In [2], the data is streamed to the calling function. Since the calling function simply has to find the maximum value — the word which comes latest in lexicographic sort order — it can process the stream of data without having to store anything more than the maximum value seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q and A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  Questions of Style (See Slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Coding Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedural vs Declarative Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have just seen how the same task can be performed in different ways, with implications for efficiency. Another factor influencing program development is programming style. Consider the following program to compute the average length of words in the Brown Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.corpus.brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokens:\n",
    "    count+=1\n",
    "    total+=len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.401545438271973"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this program we use the variable count to keep track of the number of tokens seen, and total to store the combined length of all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The two variables are just like a CPU's registers, accumulating values at many intermediate stages, values that are meaningless until the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We say that this program is written in a procedural style, dictating the machine operations step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now consider the following program that computes the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(len(t) for t in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "print(total / len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first line uses a generator expression to sum the token lengths, while the second line computes the average as before. Each line of code performs a complete, meaningful task, which can be understood in terms of high-level properties like: \"total is the sum of the lengths of the tokens\". Implementation details are left to the Python interpreter. The second program uses a built-in function, and constitutes programming at a more abstract level; the resulting code is more declarative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another case where a loop variable seems to be necessary is for printing a counter with each line of output. Instead, we can use enumerate(), which processes a sequence s and produces a tuple of the form (i, s[i]) for each item in s, starting with (0, s[0]). Here we enumerate the key-value pairs of the frequency distribution, resulting in nested tuples (rank, (word, count)). We print rank+1 so that the counting appears to start from 1, as required when producing a list of ranked items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = [word for (word, count) in fd.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'and', 'to', 'a', 'in', 'that', 'is']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'the'),\n",
       " (1, ','),\n",
       " (2, '.'),\n",
       " (3, 'of'),\n",
       " (4, 'and'),\n",
       " (5, 'to'),\n",
       " (6, 'a'),\n",
       " (7, 'in'),\n",
       " (8, 'that'),\n",
       " (9, 'is')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(most_common_words[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    "for rank, word in enumerate(most_common_words):\n",
    "        cumulative += fd.freq(word)\n",
    "        print(\"%3d %6.2f%% %s\" % (rank + 1, cumulative * 100, word))\n",
    "        if cumulative > 0.25: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Use enumerate () fuction to rank the cumulative frequency (30%) of the most commmon words in web text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=nltk.FreqDist(nltk.corpus.webtext.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = [word for (word,count) in df.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   4.25% .\n",
      "  2   4.40% :\n",
      "  3   9.43% ,\n",
      "  4   9.46% '\n",
      "  5   9.90% I\n",
      "  6  15.30% the\n",
      "  7  17.52% to\n",
      "  8  19.40% a\n",
      "  9  19.64% you\n",
      " 10  20.04% ?\n",
      " 11  21.73% in\n",
      " 12  24.13% and\n",
      " 13  24.27% !\n",
      " 14  24.27% #\n",
      " 15  24.27% t\n",
      " 16  24.27% -\n",
      " 17  24.27% s\n",
      " 18  24.82% on\n",
      " 19  27.93% of\n",
      " 20  28.79% is\n",
      " 21  29.37% it\n",
      " 22  29.37% \"\n",
      " 23  29.75% not\n",
      " 24  30.64% that\n"
     ]
    }
   ],
   "source": [
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"%3d %6.2f%% %s\" % (rank +1, cumulative *100, word))\n",
    "    if cumulative > 0.3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's sometimes tempting to use loop variables to store a maximum or minimum value seen so far. Let's use this method to find the longest word in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "        longest = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unextinguishable'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, a more transparent solution uses two list comprehensions, both having forms that should be familiar by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max(len(word) for word in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that our first solution found the first word having the longest length, while the second solution found all of the longest words (which is usually what we would want). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Use a list comprehension to find out the longest words in \"shakespeare-macbeth.txt\" in gutenberg corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(len(word) for word in text)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voluptuousnesse']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Legitimate Uses for Counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are cases where we still want to use loop variables in a list comprehension. For example, we need to use a loop variable to extract successive overlapping n-grams from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is quite tricky to get the range of the loop variable right. Since this is a common operation in NLP, NLTK supports it with functions bigrams(text) and trigrams(text), and a general purpose ngrams(text, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'dog'),\n",
       " ('dog', 'gave'),\n",
       " ('gave', 'John'),\n",
       " ('John', 'the'),\n",
       " ('the', 'newspaper')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'dog', 'gave'),\n",
       " ('dog', 'gave', 'John'),\n",
       " ('gave', 'John', 'the'),\n",
       " ('John', 'the', 'newspaper')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'dog', 'gave', 'John'),\n",
       " ('dog', 'gave', 'John', 'the'),\n",
       " ('gave', 'John', 'the', 'newspaper')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(sent,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3   Functions: The Foundation of Structured Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Inputs and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We pass information to functions using a function's parameters, the parenthesized list of variables and constants following the function's name in the function definition. Here's a complete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(msg, num):\n",
    "    return ' '.join([msg] * num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = 'Monty Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repeat(monty, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is not necessary to have any parameters, as we see in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monty():\n",
    "    return \"Monty Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function usually communicates its results back to the calling program via the return statement, as we have just seen. To the calling program, it looks as if the function call had been replaced with the function's result, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(monty(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat('Monty Python', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the following three sort functions. The third one is dangerous because a programmer could use it without realizing that it had modified its input. In general, functions should modify the contents of a parameter (my_sort1()), or return a value (my_sort2()), not both (my_sort3())."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### good: modifies its argument, no return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort1(mylist):\n",
    "    mylist.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### good: doesn't touch its argument, returns value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort2(mylist):\n",
    "    return sorted(mylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bad: modifies its argument and also returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort3(mylist):\n",
    "    mylist.sort()\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Parameter Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python does not allow us to declare the type of a variable when we write a program, and this permits us to define functions that are flexible about the type of their arguments. For example, a tagger might expect a sequence of words, but it wouldn't care whether this sequence is expressed as a list or a tuple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, often we want to write programs for later use by others, and want to program in a defensive style, providing useful warnings when functions have not been invoked correctly. The author of the following tag() function assumed that its argument would always be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The author of this function could take some extra steps to ensure that the word parameter of the tag() function is a string. A naive approach would be to check the type of the argument using if not type(word) is str, and if word is not a string, to simply return Python's special empty value, None. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a slight improvement, because the function is checking the type of the argument, and trying to return a \"special\", diagnostic value for the wrong input. However, it is also dangerous because the calling program may not detect that None is intended as a \"special\" value, and this diagnostic return value may then be propagated to other parts of the program with unpredictable consequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This approach also fails if the word is a Unicode string, which has type unicode, not str. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here's a better solution, using an assert statement together with Python's basestring type that generalizes over both unicode and str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    assert isinstance(word, str),\"argument to tag() must be a string\"\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "argument to tag() must be a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbut\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscratch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [159]\u001b[0m, in \u001b[0;36mtag\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtag\u001b[39m(word):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(word, \u001b[38;5;28mstr\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument to tag() must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdet\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: argument to tag() must be a string"
     ]
    }
   ],
   "source": [
    "tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the assert statement fails, it will produce an error that cannot be ignored, since it halts program execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well-structured programs usually make extensive use of functions. When a block of program code grows longer than 10-20 lines, it is a great help to readability if the code is broken up into one or more functions, each one having a clear purpose. This is analogous to the way a good essay is divided into paragraphs, each expressing one main idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions provide an important kind of abstraction. They allow us to group multiple actions into a single, complex action, and associate a name with it. (Compare this with the way we combine the actions of go and bring back into a single more complex action fetch.) When we use functions, the main program can be written at a higher level of abstraction, making its structure transparent, e.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appropriate use of functions makes programs more readable and maintainable. Additionally, it becomes possible to reimplement a function — replacing the function's body with more efficient code — without having to be concerned with the rest of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the freq_words function in 4.3. It updates the contents of a frequency distribution that is passed in as a parameter, and it also prints a list of the n most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, freqdist, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    for word in nltk.word_tokenize(raw):\n",
    "        freqdist[word.lower()] += 1\n",
    "    result = []\n",
    "    for word, count in freqdist.most_common(n):\n",
    "        result = result + [word]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'documents', 'and', ',', 'archives', '.', 'national', 'constitution', 'founding', 'to', 'declaration', 'for', 'a', 'visit', 'online', 'freedom', \"'s\", '·', 'us', 'states', 'rights', 'or', 'charters', 'america', 'independence', 'united', 'home', 'search', 'resources']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "freq_words(constitution, fd, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function has a number of problems. The function has two side-effects: it modifies the contents of its second parameter, and it prints a selection of the results it has computed. The function would be easier to understand and to reuse elsewhere if we initialize the FreqDist() object inside the function (in the same place it is populated), and if we moved the selection and display of results to the calling program. Given that its task is to identify frequent words, it should probably just return a list, not the whole frequency distribution. In 4.4 we refactor this function, and simplify its interface by dropping the freqdist parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    text = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    fd = nltk.FreqDist(word.lower() for word in nltk.word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '}',\n",
       " '\\\\',\n",
       " 'of',\n",
       " 'is',\n",
       " 'a',\n",
       " 'to',\n",
       " 'in',\n",
       " 'for',\n",
       " 'and',\n",
       " ':',\n",
       " 'with',\n",
       " '[',\n",
       " ']',\n",
       " 'matrix',\n",
       " 'pca',\n",
       " 'that',\n",
       " 'be',\n",
       " 'as',\n",
       " 'can',\n",
       " 'data',\n",
       " 'components',\n",
       " 'dictionary',\n",
       " '=',\n",
       " 'it']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words(constitution, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The readability and usability of the freq_words function is improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Choose your own webpage( in html format) and use the above code to output the 20 most common words in this web page. Please get rid of stop words, numbers and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = \"https://scikit-learn.org/stable/modules/decomposition.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '}',\n",
       " '\\\\',\n",
       " 'of',\n",
       " 'is',\n",
       " 'a',\n",
       " 'to',\n",
       " 'in',\n",
       " 'for',\n",
       " 'and',\n",
       " ':',\n",
       " 'with',\n",
       " '[',\n",
       " ']',\n",
       " 'matrix']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words(decomposition, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q and A and Take a Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Doing More with Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section discusses more advanced features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions as Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far the arguments we have passed into functions have been simple objects like strings, or structured objects like lists. Python also lets us pass a function as an argument to another function. Now we can abstract out the operation, and apply a different operation on the same data. As the following examples show, we can pass the built-in function len() or a user-defined function last_letter() as arguments to another function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Now we can abstract out the operation, and apply a different operation on the same data. As the following examples show, we can pass the built-in function len() or a user-defined function last_letter() as arguments to another function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "        'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_property(prop):\n",
    "    return [prop(word) for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(word):\n",
    "    return word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(last_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python provides us with one more way to define functions as arguments to other functions, so-called lambda expressions. Supposing there was no need to use the above last_letter() function in multiple places, and thus no need to give it a name. We can equivalently write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " extract_property(lambda w: len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accumulative Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These functions start by initializing some storage, and iterate over input to build it up, before returning some final object (a large structure or aggregated result). A standard way to do this is to initialize an empty list, accumulate the material, then return the list, as shown in function search1() in 4.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search1('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search2('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function search2() is a generator. The first time this function is called, it gets as far as the yield statement and pauses. The calling program gets the first word and does any necessary processing. Once the calling program is ready for another word, execution of the function is continued from where it stopped, until the next time it encounters a yield statement. This approach is typically more efficient, as the function only generates the data as it is required by the calling program, and does not need to allocate additional memory to store the output (cf. our discussion of generator expressions above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-Order Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start by defining a function is_content_word() which checks whether a word is from the open class of content words. We use this function as the first parameter of filter(), which applies the function to each item in the sequence contained in its second parameter, and only retains the items for which the function returns True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_word(word):\n",
    "    return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "      'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another higher-order function is map(), which applies a function to every item in a sequence. It is a general version of the extract_property() function we saw in 4.5. Here is a simple way to find the average length of a sentence in the news section of the Brown Corpus, followed by an equivalent version with list comprehension calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lengths = list(map(len, nltk.corpus.brown.sents(categories='news')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 43, 35, 37, 24, 24, 43, 2, 26, 25]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in nltk.corpus.brown.sents(categories='news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When there are a lot of parameters it is easy to get confused about the correct order. Instead we can refer to parameters by name, and even assign them a default value just in case one was not provided by the calling program. Now the parameters can be specified in any order, and can be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(msg='<empty>', num=1):\n",
    "    return msg * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<empty><empty><empty>'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AliceAliceAliceAliceAlice'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=5, msg='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are called keyword arguments. If we mix these two kinds of parameters, then we must ensure that the unnamed parameters precede the named ones. It has to be this way, since unnamed parameters are defined by position. We can define a function that takes an arbitrary number of unnamed and named parameters, and access them via an in-place list of arguments *args and an \"in-place dictionary\" of keyword arguments **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow', 'test')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "generic(1, \"African swallow\",\"test\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_sum(*args):\n",
    "    return sum(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any_sum(1,4,5,6,9,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_sum(*num):\n",
    "    return sum(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when to use the arbitrary number of keyword arguments, just give you a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_party_order_function(name, number, location):\n",
    "    return f\"{name} ordered {number} items for the store in {location}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_party_order_function(name, number, location):\n",
    "    return \"{} ordered {} items for the store in {}.\".format(name, number, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John ordered 3 items for the store in NYC.'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_party_order_function('John', 3, 'NYC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_order_function(date, **kwargs):\n",
    "    return f\"Placed order on {date}: \" + third_party_order_function(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Placed order on 2020-09: Alice ordered 5 items for the store in Chicago.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_order_function('2020-09', name='Alice', number=5, location='Chicago')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Here's another illustration of this aspect of Python syntax, for the zip() function which operates on a variable number of arguments. We'll use the variable name *song to demonstrate that there's nothing special about the name *args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = [['four', 'calling', 'birds'],\n",
    "       ['three', 'French', 'hens'],\n",
    "       ['two', 'turtle', 'doves']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(song[0], song[1], song[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It should be clear from the above example that typing *song is just a convenient shorthand, and equivalent to typing out song[0], song[1], song[2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here's another example of the use of keyword arguments in a function definition, along with three equivalent ways to call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10):\n",
    "    text = open(file).read()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    freqdist = nltk.FreqDist(t for t in tokens if len(t) >= min)\n",
    "    return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fw = freq_words('document.txt', 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fw = freq_words('document.txt', min=4, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fw=freq_words('document.txt', num=10, min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5  A Sample of Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python has hundreds of third-party libraries, specialized software packages that extend the functionality of Python. NLTK is one such library. To realize the full power of Python programming, you should become familiar with several other libraries. Most of these will need to be manually installed on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use Python's CSV library to read and write files stored in this format. For example, we can open a CSV file called lexicon.csv and iterate over its rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open(\"lexicon.csv\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep\\tsli:p\\tv.i\\ta condition of body and mind…']\n",
      "['walk\\two:k\\tv.intr\\tprogress by lifting and setting down each foot…']\n",
      "['wake\\tweik\\tintrans\\tcease to sleep']\n"
     ]
    }
   ],
   "source": [
    "for row in csv.reader(input_file): \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each row is just a list of strings. If any fields contain numerical data, they will appear as strings, and will have to be converted using int() or float()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy (See Slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The NumPy package provides substantial support for numerical processing in Python. NumPy has a multi-dimensional array object, which is easy to initialize and access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The NumPy package provides substantial support for numerical processing in Python. NumPy has a multi-dimensional array object, which is easy to initialize and access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = array([ [[0,0,0], [1,1,1], [2,2,2]],\n",
    "                [[3,3,3], [4,4,4], [5,5,5]],\n",
    "                  [[6,6,6], [7,7,7], [8,8,8]] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [6, 7, 8],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube[2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7],\n",
       "       [8, 8, 8]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube[2,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
